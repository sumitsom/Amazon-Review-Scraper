{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sumit\\Desktop\\Amazon Sentiment Aanalysis\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\Sumit\\Desktop\\Amazon Sentiment Aanalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Amazon Product Url- https://www.amazon.in/Samsung-Galaxy-Midnight-Blue-Storage/dp/B07HGJJ559/ref=sr_1_1?crid=KY10W2S37OIQ&dchild=1&keywords=samsung+galaxy+m21&qid=1606918644&sprefix=samsu%2Caps%2C317&sr=8-1\n",
      "----------Extraction of data is complete. Check json file.----------\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "import json\n",
    "\n",
    "# For ignoring SSL certificate errors\n",
    "\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url=input(\"Enter Amazon Product Url- \")\n",
    "\n",
    "html = urllib.request.urlopen(url, context=ctx).read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "html = soup.prettify('utf-8')\n",
    "product_json = {}\n",
    "\n",
    "# This block of code will help extract the Brand of the item\n",
    "\n",
    "for divs in soup.findAll('div', attrs={'class': 'a-box-group'}):\n",
    "    try:\n",
    "        product_json['brand'] = divs['data-brand']\n",
    "        break\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# This block of code will help extract the Prodcut Title of the item\n",
    "\n",
    "for spans in soup.findAll('span', attrs={'id': 'productTitle'}):\n",
    "    name_of_product = spans.text.strip()\n",
    "    product_json['name'] = name_of_product\n",
    "    break\n",
    "\n",
    "# This block of code will help extract the price of the item in dollars\n",
    "\n",
    "for divs in soup.findAll('div'):\n",
    "    try:\n",
    "        price = str(divs['data-asin-price'])\n",
    "        product_json['price'] = '$' + price\n",
    "        break\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# This block of code will help extract the image of the item in dollars\n",
    "\n",
    "for divs in soup.findAll('div', attrs={'id': 'rwImages_hidden'}):\n",
    "    for img_tag in divs.findAll('img', attrs={'style': 'display:none;'\n",
    "                                }):\n",
    "        product_json['img-url'] = img_tag['src']\n",
    "        break\n",
    "\n",
    "# This block of code will help extract the average star rating of the product\n",
    "\n",
    "for i_tags in soup.findAll('i',\n",
    "                           attrs={'data-hook': 'average-star-rating'}):\n",
    "    for spans in i_tags.findAll('span', attrs={'class': 'a-icon-alt'}):\n",
    "        product_json['star-rating'] = spans.text.strip()\n",
    "        break\n",
    "\n",
    "# This block of code will help extract the number of customer reviews of the product\n",
    "\n",
    "for spans in soup.findAll('span', attrs={'id': 'acrCustomerReviewText'\n",
    "                          }):\n",
    "    if spans.text:\n",
    "        review_count = spans.text.strip()\n",
    "        product_json['customer-reviews-count'] = review_count\n",
    "        break\n",
    "\n",
    "# This block of code will help extract top specifications and details of the product\n",
    "\n",
    "product_json['details'] = []\n",
    "for ul_tags in soup.findAll('ul',\n",
    "                            attrs={'class': 'a-unordered-list a-vertical a-spacing-none'\n",
    "                            }):\n",
    "    for li_tags in ul_tags.findAll('li'):\n",
    "        for spans in li_tags.findAll('span',\n",
    "                attrs={'class': 'a-list-item'}, text=True,\n",
    "                recursive=False):\n",
    "            product_json['details'].append(spans.text.strip())\n",
    "\n",
    "# This block of code will help extract the short reviews of the product\n",
    "\n",
    "product_json['short-reviews'] = []\n",
    "for a_tags in soup.findAll('a',\n",
    "                           attrs={'class': 'a-size-base a-link-normal review-title a-color-base a-text-bold'\n",
    "                           }):\n",
    "    short_review = a_tags.text.strip()\n",
    "    product_json['short-reviews'].append(short_review)\n",
    "\n",
    "# This block of code will help extract the long reviews of the product\n",
    "\n",
    "product_json['long-reviews'] = []\n",
    "for divs in soup.findAll('div', attrs={'data-hook': 'review-collapsed'\n",
    "                         }):\n",
    "    long_review = divs.text.strip()\n",
    "    product_json['long-reviews'].append(long_review)\n",
    "\n",
    "# Saving the scraped html file\n",
    "\n",
    "with open('output_file.html', 'wb') as file:\n",
    "    file.write(html)\n",
    "\n",
    "# Saving the scraped data in json format\n",
    "\n",
    "with open('product.json', 'w') as outfile:\n",
    "    json.dump(product_json, outfile, indent=4)\n",
    "print ('----------Extraction of data is complete. Check json file.----------')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
